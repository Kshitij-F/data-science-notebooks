{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/kshitij/Documents/dataScience/textClassification_IMDB/sentiment_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_path = os.path.join(data_path, 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kshitij/Documents/dataScience/textClassification_IMDB/sentiment_analysis/aclImdb'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for category in ['pos', 'neg']:\n",
    "    train_path = os.path.join(imdb_data_path, 'train', category)\n",
    "    for fname in sorted(os.listdir(train_path)):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(train_path, fname)) as f:\n",
    "                train_texts.append(f.read())\n",
    "            train_labels.append(0 if category == 'neg' else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = []\n",
    "test_labels = []\n",
    "for category in ['pos', 'neg']:\n",
    "    test_path = os.path.join(imdb_data_path, 'test', category)\n",
    "    for fname in sorted(os.listdir(test_path)):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(test_path, fname)) as f:\n",
    "                test_texts.append(f.read())\n",
    "            test_labels.append(0 if category == 'neg' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training data and labels. T\n",
    "random.seed(seed)\n",
    "random.shuffle(train_texts)\n",
    "random.seed(seed)\n",
    "random.shuffle(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in train_texts])\n",
    "plt.xlabel('Length of a sample')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Sample length distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization parameters\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "NGRAM_RANGE = (1, 2)\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitij/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1569: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Learn vocabulary from training texts and vectorize training texts.\n",
    "x_train = vectorizer.fit_transform(train_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize validation texts.\n",
    "#x_val = vectorizer.transform(val_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 436686)\t0.02919573530225501\n",
      "  (0, 436415)\t0.035663496901798576\n",
      "  (0, 436097)\t0.01982615441258547\n",
      "  (0, 428593)\t0.029185442353921075\n",
      "  (0, 427126)\t0.06187935126620944\n",
      "  (0, 426772)\t0.0167661351978179\n",
      "  (0, 426691)\t0.041391480358561175\n",
      "  (0, 426688)\t0.035320596405992964\n",
      "  (0, 423999)\t0.020038349175493447\n",
      "  (0, 423694)\t0.18031252260348699\n",
      "  (0, 422809)\t0.04417636967508156\n",
      "  (0, 420797)\t0.026808134056327485\n",
      "  (0, 420226)\t0.012451823342025409\n",
      "  (0, 420184)\t0.0551002311020587\n",
      "  (0, 420151)\t0.033300196830641955\n",
      "  (0, 420030)\t0.028560034514764403\n",
      "  (0, 419410)\t0.01186208607902722\n",
      "  (0, 418909)\t0.031445397743511565\n",
      "  (0, 418105)\t0.014228366646665264\n",
      "  (0, 416036)\t0.03661470233861506\n",
      "  (0, 415760)\t0.014939126889031937\n",
      "  (0, 415409)\t0.028923680189604443\n",
      "  (0, 415299)\t0.01774379968552041\n",
      "  (0, 415084)\t0.025165549567980214\n",
      "  (0, 414830)\t0.015548854693674567\n",
      "  :\t:\n",
      "  (0, 22081)\t0.04788016474730238\n",
      "  (0, 21141)\t0.03104344779139404\n",
      "  (0, 19073)\t0.06187935126620944\n",
      "  (0, 18752)\t0.06380487120022792\n",
      "  (0, 16933)\t0.04490066941874055\n",
      "  (0, 15476)\t0.0551002311020587\n",
      "  (0, 15305)\t0.019929541557390178\n",
      "  (0, 13864)\t0.023064084767423092\n",
      "  (0, 13766)\t0.026304541428197423\n",
      "  (0, 13011)\t0.01778256811312095\n",
      "  (0, 12150)\t0.04621230553671938\n",
      "  (0, 12115)\t0.020331570661420613\n",
      "  (0, 10013)\t0.03352460778295374\n",
      "  (0, 9610)\t0.015204368695920987\n",
      "  (0, 9140)\t0.0551002311020587\n",
      "  (0, 9139)\t0.04319148893033894\n",
      "  (0, 8610)\t0.04708284811125522\n",
      "  (0, 8578)\t0.029299620265895977\n",
      "  (0, 6341)\t0.0294911376723713\n",
      "  (0, 6018)\t0.015668477237009967\n",
      "  (0, 5883)\t0.05760220265161052\n",
      "  (0, 5852)\t0.02561007085781409\n",
      "  (0, 4397)\t0.038299133340346854\n",
      "  (0, 3639)\t0.04082366660094003\n",
      "  (0, 3499)\t0.023057176872468173\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 438613)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 'k' of the vectorized features. #20k\n",
    "selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "selector.fit(x_train, train_labels)\n",
    "x_train = selector.transform(x_train).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape #top 20k features , where = how much each token contributes to label prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build, Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_last_layer_units_and_activation(num_classes):\n",
    "    \"\"\"Gets the # units and activation function for the last network layer.\n",
    "\n",
    "    # Arguments\n",
    "        num_classes: int, number of classes.\n",
    "\n",
    "    # Returns\n",
    "        units, activation values.\n",
    "    \"\"\"\n",
    "    if num_classes == 2:\n",
    "        activation = 'sigmoid'\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        units = num_classes\n",
    "    return units, activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimetrnsion of the layers.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "        num_classes: int, number of output classes.\n",
    "\n",
    "    # Returns\n",
    "        An MLP model instance.\n",
    "    \"\"\"\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=op_units, activation=op_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"POSSIBLE SPOILERS<br /><br />The Spy Who Shagged Me is a muchly overrated and over-hyped sequel. International Man of Mystery came straight out of the blue. It was a lone star that few people had heard of. But it was stunningly original, had sophisticated humour and ample humour, always kept in good taste, and had a brilliant cast. The Spy Who Shagged Me was a lot more commercially advertised and hyped about.<br /><br />OK I'll admit, the first time I saw this film I thought it was very funny, but it's only after watching it two or three times that you see all the flaws. The acting was OK, but Heather Graham cannot act. Her performance didn't seem very convincing and she wasn't near as good as Liz Hurley was in the first one. Those characters who bloomed in the first one, (Scott Evil, Number 2 etc.) are thrown into the background hear and don't get many stand-alone scenes. The film is simply overrun with cameos.<br /><br />In particular, I hated the way they totally disregarded some of the scenes in IMOM. When they killed off Vanessa at the start and had Basil sat that he knew she was a fembot all along. What was the point of that? They killed off Number 2 in the first one, and now they bring him back with no explanation whatsoever. This is supposed to be a spy-spoof, I don't think any of the characters even hold a gun in the film. It just goes on a trail, further and further away from the point.<br /><br />The new characters are very unwelcome. The whole Mini-Me `make fun of my size' joke gets old very quickly. Fat Bastard is just a lame excuse for gross-out humour. In total there's about two or three good jokes. The rest are either tasteless or rehashed from IMOM.<br /><br />If this were the first movie of the series then I'd probably be easier on it. But the series started on a note of dry wit and then plummeted down to a level of gross out humour. So I say, only watch this film if you haven't seen its predecessor, because The Spy Who Shagged Me is one ultimate disappointment.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ngram_model(data,\n",
    "                      learning_rate=1e-3,\n",
    "                      epochs=1000,\n",
    "                      batch_size=128,\n",
    "                      layers=2,\n",
    "                      units=64,\n",
    "                      dropout_rate=0.2):\n",
    "    \"\"\"Trains n-gram model on the given dataset.\n",
    "\n",
    "    # Arguments\n",
    "        data: tuples of training and test texts and labels.\n",
    "        learning_rate: float, learning rate for training model.\n",
    "        epochs: int, number of epochs.\n",
    "        batch_size: int, number of samples per batch.\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of Dense layers in the model.\n",
    "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: If validation data has label values which were not seen\n",
    "            in the training data.\n",
    "    \"\"\"\n",
    "    # Get the data.\n",
    "    (train_texts, train_labels), (val_texts, val_labels) = data\n",
    "\n",
    "    # Verify that validation labels are in the same range as training labels.\n",
    "    num_classes = explore_data.get_num_classes(train_labels)\n",
    "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
    "    if len(unexpected_labels):\n",
    "        raise ValueError('Unexpected label values found in the validation set:'\n",
    "                         ' {unexpected_labels}. Please make sure that the '\n",
    "                         'labels in the validation set are in the same range '\n",
    "                         'as training labels.'.format(\n",
    "                             unexpected_labels=unexpected_labels))\n",
    "\n",
    "    # Vectorize texts.\n",
    "    x_train, x_val = vectorize_data.ngram_vectorize(\n",
    "        train_texts, train_labels, val_texts)\n",
    "\n",
    "    # Create model instance.\n",
    "    model = build_model.mlp_model(layers=layers,\n",
    "                                  units=units,\n",
    "                                  dropout_rate=dropout_rate,\n",
    "                                  input_shape=x_train.shape[1:],\n",
    "                                  num_classes=num_classes)\n",
    "\n",
    "    # Compile model with learning parameters.\n",
    "    if num_classes == 2:\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "\n",
    "    # Create callback for early stopping on validation loss. If the loss does\n",
    "    # not decrease in two consecutive tries, stop training.\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=2)]\n",
    "\n",
    "    # Train and validate model.\n",
    "    history = model.fit(\n",
    "            x_train,\n",
    "            train_labels,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(x_val, val_labels),\n",
    "            verbose=2,  # Logs once per epoch.\n",
    "            batch_size=batch_size)\n",
    "\n",
    "    # Print results.\n",
    "    history = history.history\n",
    "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
    "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
    "\n",
    "    # Save model.\n",
    "    model.save('IMDb_mlp_model.h5')\n",
    "    return history['val_acc'][-1], history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_ngram_model(x_train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_texts, train_labels), (val_texts, val_labels) = data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
